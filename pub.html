
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Xin Li's Personal Page</title>
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <!--Montserrat font-->
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css" />
    <script src="https://unpkg.com/feather-icons"></script>
  </head>
  <body>   
    <section>
      <!-- SOCIAL SECTION -->
      <section class="image-section w3-quarter w3-fixed w3-padding-small">
        <!--IMAGE/AVATAR-->
        <img src="avatar.png" class="w3-circle w3-border w3-border-sand" style="border-width: 3px !important;"/>
        <!--SCIAL NETWORK BUTTONS-->
        <div>
			<font color="#FFFFFF">
		<table><tr valign="top">
        <td><img style="width:8em; height:auto" /></td>
        <td align="left">
            <p><span style="font-size: 110%"><b>Xin Li, Ph.D.</b></span></p>
            <p>
                Senoir Scientist, AIQ
            </p>
            <p>
                E-mail: <b>xinli_uestc@hotmail.com</b><br>
			</p>
			
        </td>
			</tr></table></font>
          
        </div>

      </section>

      <!--CV CONTENT SECTION-->
      <section class="w3-threequarter w3-padding-large w3-right">
        <!--DESKTOP NAVIGATION-->
        <div class="w3-container w3-padding-large w3-border-bottom w3-hide-small">
          <a href="index.html" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-green">Home</a>
        </div>
        <div class="content-container w3-margin-top-2">       
			<td id="layout-content">

    <h1 style="margin-top: 0em">Publications</h1><br>
    <p>An asterisk (*) beside authors' names indicates equal contribution.</p>
    <div>
        <h2><hr><a name="conference"></a>2022</h2>
        <ol>
			<li>
			<p>
			Learning Optical Flow with Kernel Patch Attention<br>
			Ao Luo, Fan Yang, <b>Xin Li</b> and Shuaicheng Liu.<br>
			In <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022.</i><br>
			[PDF]
			</p>
		</li>
		<li>
			<p>
			Nested Architecture Search for Point Cloud Semantic Segmentation<br>
			Fan Yang, <b>Xin Li</b> and Jianbing Shen.<br>
			<i>IEEE Transactions on Image Processing (TIP), 2022.</i><br>
			[PDF]
			</p>
		</li>
                <li>
			<p>
			Learning Optical Flow with Adaptive Graph Reasoning<br>
			Ao Luo, Fan Yang, Kunming Luo, <b>Xin Li</b>, Haoqiang Fan and Shuaicheng Liu.<br>
			In <i>Proceedings of 36th AAAI Conference on Artificial Intelligence (AAAI), 2022.</i><br>
			[<a href="">PDF</a>]
			</p>
			</li>
		<li>
			<p>
			Co-Communication Graph Convolutional Network for Multi-View Crowd Counting<br>
			Qiang Zhai, Fan Yang, <b>Xin Li</b>, Guo-Sen Xie, Hong Cheng, Zicheng Liu.<br>
			In <i>IEEE Transactions on Multimedia (TMM), 2022.</i><br>
			[<a href="">PDF</a>]
			</p>
			</li>
		<li>
			<p>
			MGL: Mutual Graph Learning for Camouflaged Object Detection<br>
			Qiang Zhai, <b>Xin Li</b>, Fan Yang, Zhicheng Jiao, Ping Luo, Hong Cheng, Zicheng Liu.<br>
			In <i>IEEE Transactions on Image Processing (TIP), 2022.</i><br>
			[<a href="">PDF</a>]
			</p>
			</li>
		</ol>
		<h2><hr><a name="conference"></a>2021</h2>
		<ol>
            <li>
			<p>
			Uncertainty-Guided Transformer Reasoning for Camouflaged Object Detection<br>
			Fan Yang*, Qiang Zhai*, <b>Xin Li</b>, Rui Huang, Ao Luo, Hong Cheng and Deng-Ping Fan.<br>
			In <i>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021.</i><br>
			[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_Uncertainty-Guided_Transformer_Reasoning_for_Camouflaged_Object_Detection_ICCV_2021_paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/fanyang587/UGTR" target="_blank">Github</a>]
			</p>
			</li>
            <li>
			<p>
			Mutual Graph Learning for Camouflaged Object Detection<br>
			Qiang Zhai*, Xin Li*, Fan Yang, Chenglizhao Chen, Hong Cheng and Deng-Ping Fan.<br>
			In <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</i><br>
			[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhai_Mutual_Graph_Learning_for_Camouflaged_Object_Detection_CVPR_2021_paper.pdf" target="_blank">PDF</a>] [<a href="https://arxiv.org/pdf/2104.02613.pdf" target="_blank">arXiv</a>][<a href="https://github.com/fanyang587/MGL" target="_blank">Github</a>]
			</p>
			</li>
            <li>
			<p>
			Probabilistic Model Distillation for Semantic Correspondence<br>
			<b>Xin Li</b>, Deng-Ping Fan, Fan Yang, Ao Luo, Hong Cheng, Zicheng Liu.<br>
			In <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</i><br>
			[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Probabilistic_Model_Distillation_for_Semantic_Correspondence_CVPR_2021_paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/fanyang587/PMD" target="_blank">Github</a>]
			</p>
			</li>
            <li>
			<p>
			Robust Scene Parsing by Mining Supportive Knowledge from Dataset<br>
			Ao Luo*, Fan Yang*, <b>Xin Li</b>, Yuezun Li, Zhicheng Jiao, Hong Cheng and Siwei Lyu.<br>
			<i>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2021.</i><br>
			[<a href="https://ieeexplore.ieee.org/abstract/document/9537741" target="_blank">PDF</a>]
			</p>
			</li>
            <li>
			<p>
			Exploring Graph-Structured Semantics for Cross-Modal Retrieval<br>
			Lei Zhang, Leiting Chen, Chuan Zhou, Fan Yang and Xin Li.<br>
			<i>ACM International Conference on Multimedia (ACM MM), 2021.</i><br>
			[<a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475567" target="_blank">PDF</a>]
			</p>
			</li>
            
            <li>
			<p>
			Reconstructing perceived images from brain activity by visually-guided cognitive representation and adversarial learning<br>
			Ziqi Ren, Jie Li, Xuetong Xue, <b>Xin Li</b>, Fan Yang, Zhicheng Jiao, Xinbo Gao.<br>
			<i>NeuroImage, 2021.</i><br>
			[PDF] [<a href="https://arxiv.org/pdf/1906.12181.pdf" target="_blank">arXiv</a>]
			</p>
			</li>
            <li>
			<p>
			EFRNet: Efficient Feature Reconstructing Network for Real-Time Scene Parsing<br>
			<b>Xin Li</b>, Fan Yang, Ao Luo, Zhicheng Jiao, Hong Cheng and Zicheng Liu.<br>
			<i>IEEE Transactions on Multimedia (TMM), 2021.</i><br>
			[<a href="https://ieeexplore.ieee.org/abstract/document/9457186" target="_blank">PDF</a>]
			</p>
			</li>
            <li>
			<p>
			EKENet: Efficient Knowledge Enhanced Network for Real-Time Scene Parsing<br>
			Ao Luo, Fan Yang, <b>Xin Li</b>, Rui Huang and Hong Cheng.<br>
			<i>Pattern Recognition, 2021.</i><br>
			[<a href="https://ieeexplore.ieee.org/abstract/document/9457186" target="_blank">PDF</a>]
			</p>
			</li>
        </ol>
		<h2><hr><a name="conference"></a>2020</h2>
		<ol>
			<li>
			<p>
			MSB-FCN: Multi-Scale Bidirectional FCN for Object Skeleton Extraction<br>
			Fan Yang, <b>Xin Li</b> and Jianbing Shen.<br>
			<i>IEEE Transactions on Image Processing (TIP), 2020.</i><br>
			[<a href="https://ieeexplore.ieee.org/abstract/document/9266752" target="_blank">PDF</a>]
			</p>
			</li>
			
			<li>
			<p>
			Cascade graph neural networks for rgb-d salient object detection<br>
			Ao Luo, <b>Xin Li</b>, Fan Yang, Zhicheng Jiao, Hong Cheng and Siwei Lyu.<br>
			<i>European Conference on Computer Vision (ECCV), 2020.</i><br>
			[<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570341.pdf" target="_blank">PDF</a>] [<a href="https://arxiv.org/pdf/2008.03087.pdf" target="_blank">arXiv</a>]
			</p>
			</li>
			<li>
			<p>
			Hybrid Graph Neural Networks for Crowd Counting<br>
			Ao Luo, Fan Yang, <b>Xin Li</b>, Dong Nie, Zhicheng Jiao, Shangchen Zhou and Hong Cheng.<br>
			<i>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2020.</i><br>
			[<a href="https://ojs.aaai.org/index.php/AAAI/article/download/6839/6693" target="_blank">PDF</a>] [<a href="https://arxiv.org/pdf/2002.00092.pdf" target="_blank">arXiv</a>]
			</p>
			</li>
			<li>
			<p>
			Webly-supervised Learning for Salient Object Detection<br>
			Ao Luo, <b>Xin Li</b>, Fan Yang, Zhicheng Jiao and Hong Cheng.<br>
			<i>Pattern Recognition, 2020.</i><br>
			[<a href="https://drive.google.com/file/d/1Bh6xlGxpOSKwnvMXBDLlVH2DzgKegWp0/view" target="_blank">PDF</a>]
			</p>
			</li>
		</ol>
		<h2><hr><a name="conference"></a>Others</h2>
		<ol>
			<li>
			<p>
			Decoding EEG by Visual-guided Deep Neural Networks<br>
			Zhicheng Jiao, Haoxuan You, Fan Yang, <b>Xin Li</b>, Han Zhang and Dinggang Shen.<br>
			<i>International Joint Conference on Artificial Intelligence (IJCAI), 2019.</i><br>
			[<a href="https://www.researchgate.net/profile/Han-Zhang-193/publication/334843997_Decoding_EEG_by_Visual-guided_Deep_Neural_Networks/links/5d6e731e45851542789f2465/Decoding-EEG-by-Visual-guided-Deep-Neural-Networks.pdf" target="_blank">PDF</a>]
			</p>
			</li>
			
			<li>
			<p>
			Contour Knowledge Transfer for Salient Object Detection<br>
			<b>Xin Li</b>, Fan Yang, Hong Cheng, Wei Liu and Dinggang Shen.<br>
			<i> Proceedings of the European Conference on Computer Vision (ECCV), 2018.</i><br>
			[<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Xin_Li_Contour_Knowledge_Transfer_ECCV_2018_paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/lixin666/C2SNet" target="_blank">Github</a>]
			</p>
			</li>
			<li>
			<p>
			Multi-Scale Bidirectional FCN for Object Skeleton Extraction<br>
			Fan Yang, <b>Xin Li</b>, Hong Cheng, Yuxiao Guo, Leiting Chen and Jianping Li.<br>
			<i> Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2018.</i><br>
			[<a href="https://ojs.aaai.org/index.php/AAAI/article/download/12288/12147" target="_blank">PDF</a>] [<a href="https://github.com/fanyang587/MSB-FCN" target="_blank">Github</a>]
			</p>
			</li>
			<li>
			<p>
			Multi-Scale Cascade Network for Salient Object Detection<br>
			<b>Xin Li</b>, Fan Yang,  Hong Cheng, Junyu Chen, Yuxiao Guo and Leiting Chen.<br>
			<i> Proceedings of the ACM International Conference on Multimedia (ACM MM), 2017.</i><br>
			[<a href="https://dl.acm.org/doi/10.1145/3123266.3123290#URLTOKEN#" target="_blank">PDF</a>] [<a href="https://github.com/lixin666/MSC-NET" target="_blank">Github</a>]
			</p>
			</li>
			<li>
			<p>
			Object-aware Dense Semantic Correspondence<br>
			Fan Yang, <b>Xin Li</b>, Hong Cheng, Jianping Li and Leiting Chen.<br>
			<i> Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2017.</i><br>
			[<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Yang_Object-Aware_Dense_Semantic_CVPR_2017_paper.pdf" target="_blank">PDF</a>]
			</p>
			</li>
			<li>
			<p>
			Saliency Transfer: An Example-Based Method for Salient Object Detection<br>
			<b>Xin Li</b>, Fan Yang, Leiting Chen and Hongbin Cai.<br>
			<i> Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), 2016.</i><br>
			[<a href="https://www.ijcai.org/Proceedings/16/Papers/482.pdf" target="_blank">PDF</a>]
			</p>
			</li>
		</ol>
    </div>

</td>
        </div>

        <!--FOOTER-->
        <!-- Footer. This section contains an ad for W3Schools Spaces. You can leave it to support us. -->
        <footer class="w3-container w3-border-top w3-center w3-margin-top-4">
          <p>Â© Xin Li</p>
        <!-- End footer -->
        </footer>

        <!--END OF CV SECTION-->
      </section>      
    </section>
    <script>
      // Function to toggle mobile navigation
      function toggleNavigation() {
        let nav = document.getElementById("mobile-nav");
        if (nav.classList.contains('w3-show')) {
          nav.classList.remove('w3-show');
        } else { 
          nav.classList.add('w3-show');
        }
      }
    </script>
    <script>
      // Script to load feather icons
      feather.replace()
    </script>
  </body>
</html>
